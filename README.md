# ğŸ§  Multi-Layer Perceptrons (MLP) with Scikit-Learn and Keras

This repository contains a comprehensive walkthrough of building **Multi-Layer Perceptrons (MLPs)** for both **regression** and **classification** tasks using **Scikit-Learn** and **Keras**. The goal is to demonstrate step-by-step how to implement, train, and evaluate MLPs on real-world datasets such as the **California Housing Dataset**.

---

## ğŸ“ Notebook Overview

The `MLP.ipynb` notebook is structured into two main sections:

### ğŸ”¹ 1. Regression with MLPs (Scikit-Learn)
- Uses **Scikit-Learn's `MLPRegressor`** to model housing prices.
- Dataset: `fetch_california_housing` (features about California districts and median house values).
- Pipeline includes:
  - **StandardScaler** for feature normalization.
  - **MLPRegressor** with 3 hidden layers of 50 neurons each.
- Model evaluation:
  - **RMSE** (Root Mean Squared Error) on validation set.

### ğŸ”¹ 2. Classification with MLPs
- Transition from Scikit-Learn to **Keras** for more control and deeper architectures.
- Likely includes:
  - Building classification models using **Keras Sequential API**.
  - Evaluation using accuracy and confusion matrices (based on typical practices).

---

## ğŸ› ï¸ Libraries Used

- `sklearn.datasets` â€“ for loading the dataset
- `sklearn.neural_network` â€“ for the MLPRegressor
- `sklearn.model_selection` â€“ for training/validation/test splits
- `sklearn.pipeline` â€“ for constructing preprocessing pipelines
- `sklearn.preprocessing` â€“ for feature scaling
- `sklearn.metrics` â€“ for evaluating performance (e.g., `root_mean_squared_error`)
- `keras`, `tensorflow` â€“ expected in later sections (for more advanced MLPs)

---

## ğŸ“Š Output Metrics

The regression model is evaluated with:
- `Root Mean Squared Error (RMSE)` â€” a standard metric for regression.

Classification models are expected to be evaluated with:
- `Accuracy`
- `Confusion Matrix`
- Possibly other metrics like `Precision`, `Recall`, or `F1 Score`.

---

## ğŸš€ How to Run

1. Clone the repository:
   ```bash
   git clone https://github.com/Auwal007/Deep-learning.git
   cd mlp-regression-classification

2. Install dependencies:
    ```bash
    pip install -r requirements.txt
    ```
3. Launch the notebook:

    ```bash
    jupyter notebook MLP.ipynb
    ```
---

## ğŸ“Œ Key Takeaways

- Scikit-Learn makes it easy to quickly build MLPs for regression tasks.

- For more flexibility (e.g., custom layers, activation functions, loss functions), Keras is a better choice.

- Feature scaling is essential when working with neural networks to ensure convergence.

- Using a pipeline structure with Scikit-Learn improves code modularity and reproducibility.

## ğŸ“‚ File Structure
```bash
â”œâ”€â”€ MLP.ipynb              # Jupyter Notebook with regression and classification examples
â”œâ”€â”€ README.md              # Project overview and explanation (this file)
â”œâ”€â”€ requirements.txt       # (Optional) List of dependencies
â”œâ”€â”€ my_model.keras         # Saved Keras model file
â”œâ”€â”€ my_checkpoints.weights.h5  # Model weights checkpoint
â””â”€â”€ images/                # Folder containing images used in MLP.ipynb
```
---

## ğŸ“š References
- Scikit-Learn Documentation: https://scikit-learn.org/

- TensorFlow Keras Documentation: https://keras.io/

- California Housing Dataset: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html

## âœï¸ Author

[Muhammad ADAM
](https://x.com/M0hammadAI)

Feel free to reach out or fork the project for improvements or experiments!
